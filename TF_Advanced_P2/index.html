<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Custom Loss Function2 way to declare  string   1model.compile(loss&#x3D;&amp;#x27;mse&amp;#x27;,optimizer&#x3D;&amp;#x27;sgd&amp;#x27;) loss object   12from tensorflow.keras.losses import mean_squared_errormodel.compile(loss &#x3D;">
<meta property="og:type" content="article">
<meta property="og:title" content="Tensorflow Advanced : Part 2">
<meta property="og:url" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/index.html">
<meta property="og:site_name" content="MindCraft">
<meta property="og:description" content="Custom Loss Function2 way to declare  string   1model.compile(loss&#x3D;&amp;#x27;mse&amp;#x27;,optimizer&#x3D;&amp;#x27;sgd&amp;#x27;) loss object   12from tensorflow.keras.losses import mean_squared_errormodel.compile(loss &#x3D;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/huber_loss.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/layers.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/custom_model_1.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/res_net_1.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/res_net_2.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/res_net_3.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/res_net_4.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/res_net_5.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/res_net_6.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/mini_res_net_1.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/mini_res_net_2.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/mini_res_net_3.png">
<meta property="article:published_time" content="2021-02-12T00:00:00.000Z">
<meta property="article:modified_time" content="2021-04-27T11:23:44.960Z">
<meta property="article:author" content="Md. Zarif Ul Alam">
<meta property="article:tag" content="Algo, DS, Software &amp; What Not!">
<meta property="article:tag" content="Learning Notes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/huber_loss.png">
    
    
      
        
          <link rel="shortcut icon" href="/mindcraft/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/mindcraft/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/mindcraft/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>Tensorflow Advanced : Part 2</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/mindcraft/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" "Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/mindcraft/">Home</a></li>
         
          <li><a href="/mindcraft/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post " href="/mindcraft/TF_Advanced_P3/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post " href="/mindcraft/TF_Advanced_P1/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top " href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post " href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&text=Tensorflow Advanced : Part 2"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&is_video=false&description=Tensorflow Advanced : Part 2"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Tensorflow Advanced : Part 2&body=Check out this article: https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&name=Tensorflow Advanced : Part 2&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&t=Tensorflow Advanced : Part 2"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Custom-Loss-Function"><span class="toc-number">1.</span> <span class="toc-text">Custom Loss Function</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Loss-Function-Template"><span class="toc-number">1.1.</span> <span class="toc-text">Custom Loss Function Template</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Huber-Loss"><span class="toc-number">1.2.</span> <span class="toc-text">Huber Loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Loss-Function-Hyper-Parameter-Tuning-using-wrapper-function"><span class="toc-number">1.3.</span> <span class="toc-text">Custom Loss Function Hyper Parameter Tuning (using wrapper function)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Loss-Function-using-classes"><span class="toc-number">1.4.</span> <span class="toc-text">Custom Loss Function using classes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Contrastive-Loss-Function"><span class="toc-number">1.5.</span> <span class="toc-text">Contrastive Loss Function</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Custom-Layers"><span class="toc-number">2.</span> <span class="toc-text">Custom Layers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Layers"><span class="toc-number">2.1.</span> <span class="toc-text">Layers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Dense-Layer"><span class="toc-number">2.2.</span> <span class="toc-text">Custom Dense Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#usage-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">usage 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#usage-2"><span class="toc-number">2.2.2.</span> <span class="toc-text">usage 2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Activating-Custom-Layer"><span class="toc-number">2.3.</span> <span class="toc-text">Activating Custom Layer</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Custom-Model"><span class="toc-number">3.</span> <span class="toc-text">Custom Model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Implement-As-Class"><span class="toc-number">3.1.</span> <span class="toc-text">Implement As Class</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-Class"><span class="toc-number">3.2.</span> <span class="toc-text">Model Class</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Benefits-of-subclassing-models"><span class="toc-number">3.3.</span> <span class="toc-text">Benefits of subclassing models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Residual-Networks"><span class="toc-number">3.4.</span> <span class="toc-text">Residual Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implementing-Mini-Resnet"><span class="toc-number">3.5.</span> <span class="toc-text">Implementing Mini Resnet</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Tensorflow Advanced : Part 2
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Md. Zarif Ul Alam</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-02-12T00:00:00.000Z" itemprop="datePublished">2021-02-12</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/mindcraft/categories/Machine-Learning/">Machine Learning</a> › <a class="category-link" href="/mindcraft/categories/Machine-Learning/Tensorflow/">Tensorflow</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/mindcraft/tags/Algo-DS-Software-What-Not/" rel="tag">Algo, DS, Software & What Not!</a>, <a class="tag-link-link" href="/mindcraft/tags/Learning-Notes/" rel="tag">Learning Notes</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Custom-Loss-Function"><a href="#Custom-Loss-Function" class="headerlink" title="Custom Loss Function"></a>Custom Loss Function</h1><p>2 way to declare</p>
<ul>
<li><p>string</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mse&#x27;</span>,optimizer=<span class="string">&#x27;sgd&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>loss object</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.losses <span class="keyword">import</span> mean_squared_error</span><br><span class="line">model.<span class="built_in">compile</span>(loss = mean_squared_error , optimizer = <span class="string">&#x27;sgd&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>  we can add parameters in this second way</p>
</li>
</ul>
<h2 id="Custom-Loss-Function-Template"><a href="#Custom-Loss-Function-Template" class="headerlink" title="Custom Loss Function Template"></a>Custom Loss Function Template</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_loss_function</span>(<span class="params">y_true,y_pred</span>):</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> losses</span><br></pre></td></tr></table></figure>

<h2 id="Huber-Loss"><a href="#Huber-Loss" class="headerlink" title="Huber Loss"></a>Huber Loss</h2><p>In statistics, the Huber loss is a loss function used in robust regression, that is less sensitive to outliers in data than the squared error loss.</p>
<p><img src="huber_loss.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inputs</span></span><br><span class="line">xs = np.array([-<span class="number">1.0</span>,  <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># labels</span></span><br><span class="line">ys = np.array([-<span class="number">3.0</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">3.0</span>, <span class="number">5.0</span>, <span class="number">7.0</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_huber_loss</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">    threshold = <span class="number">1</span></span><br><span class="line">    error = y_true - y_pred</span><br><span class="line">    is_small_error = tf.<span class="built_in">abs</span>(error) &lt;= threshold</span><br><span class="line">    small_error_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">    big_error_loss = threshold * (tf.<span class="built_in">abs</span>(error) - (<span class="number">0.5</span> * threshold))</span><br><span class="line">    <span class="keyword">return</span> tf.where(is_small_error, small_error_loss, big_error_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">## tf.where</span></span><br><span class="line"><span class="comment"># is_small_error : boolean to check</span></span><br><span class="line"><span class="comment"># small_error_loss : value if True </span></span><br><span class="line"><span class="comment"># big_error_loss : value if False </span></span><br><span class="line"></span><br><span class="line">model = tf.keras.Sequential([keras.layers.Dense(units=<span class="number">1</span>, input_shape=[<span class="number">1</span>])])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>, loss=my_huber_loss)</span><br><span class="line">model.fit(xs, ys, epochs=<span class="number">500</span>,verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(model.predict([<span class="number">10.0</span>]))</span><br></pre></td></tr></table></figure>

<h2 id="Custom-Loss-Function-Hyper-Parameter-Tuning-using-wrapper-function"><a href="#Custom-Loss-Function-Hyper-Parameter-Tuning-using-wrapper-function" class="headerlink" title="Custom Loss Function Hyper Parameter Tuning (using wrapper function)"></a>Custom Loss Function Hyper Parameter Tuning (using wrapper function)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wrapper function that accepts the hyperparameter</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_huber_loss_with_threshold</span>(<span class="params">threshold</span>):</span></span><br><span class="line">    <span class="comment"># function that accepts the ground truth and predictions</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">my_huber_loss</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        error = y_true - y_pred</span><br><span class="line">        is_small_error = tf.<span class="built_in">abs</span>(error) &lt;= threshold</span><br><span class="line">        small_error_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">        big_error_loss = threshold * (tf.<span class="built_in">abs</span>(error) - (<span class="number">0.5</span> * threshold))</span><br><span class="line">        <span class="keyword">return</span> tf.where(is_small_error, small_error_loss, big_error_loss)</span><br><span class="line">    <span class="comment"># return the inner function tuned by the hyperparameter</span></span><br><span class="line">    <span class="keyword">return</span> my_huber_loss</span><br><span class="line"></span><br><span class="line"><span class="comment">###</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>, loss=my_huber_loss_with_threshold(threshold=))</span><br></pre></td></tr></table></figure>

<h2 id="Custom-Loss-Function-using-classes"><a href="#Custom-Loss-Function-using-classes" class="headerlink" title="Custom Loss Function using classes"></a>Custom Loss Function using classes</h2><p>inherits from the <code>Keras Loss class</code> and the syntax and required methods are shown below.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.losses <span class="keyword">import</span> Loss</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyHuberLoss</span>(<span class="params">Loss</span>):</span></span><br><span class="line">  </span><br><span class="line">    <span class="comment"># initialize instance attributes</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, threshold=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.threshold = threshold</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, y_true, y_pred</span>):</span></span><br><span class="line">        error = y_true - y_pred</span><br><span class="line">        is_small_error = tf.<span class="built_in">abs</span>(error) &lt;= self.threshold</span><br><span class="line">        small_error_loss = tf.square(error) / <span class="number">2</span></span><br><span class="line">        big_error_loss = self.threshold * (tf.<span class="built_in">abs</span>(error) - (<span class="number">0.5</span> * self.threshold))</span><br><span class="line">        <span class="keyword">return</span> tf.where(is_small_error, small_error_loss, big_error_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment">###</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>, loss=MyHuberLoss(threshold=<span class="number">1.02</span>))</span><br></pre></td></tr></table></figure>

<h2 id="Contrastive-Loss-Function"><a href="#Contrastive-Loss-Function" class="headerlink" title="Contrastive Loss Function"></a>Contrastive Loss Function</h2><p>State-of-the-art siamese networks tend to use some form of either contrastive loss or triplet loss when training — these loss functions are better suited for siamese networks and tend to improve accuracy. The goal of a siamese network isn’t to classify a set of image pairs but instead to differentiate between them. Essentially, contrastive loss is evaluating how good a job the siamese network is distinguishing between the image pairs. The difference is subtle but incredibly important.</p>
<p>$$<br>Y * D^2 + (1-Y) * \max(margin-D,0)^2<br>$$</p>
<ul>
<li>Y : <code>1</code> if image similar , <code>0</code> otherwise</li>
<li>D : tensor of Euclidean distance between the pair of images</li>
<li>margin : constant by which we can define if they are similar</li>
</ul>
<p>When Y = <code>1</code> , Loss = D^2 <strong>(high value)</strong></p>
<p>and when Y = <code>0</code> , Loss = max(margin-D,0)^2  <strong>(small value)</strong></p>
<p>Finally the formula becomes ,</p>
<p>$$<br>Y_{true} * Y_{pred}^{2} + (1-Y_{true}) * \max(margin-Y_{pred},0)^2<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">contrastive_loss_with_margin</span>(<span class="params">margin</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">contrastive_loss</span>(<span class="params">y_true, y_pred</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;Contrastive loss from Hadsell-et-al.&#x27;06</span></span><br><span class="line"><span class="string">        http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        square_pred = K.square(y_pred)</span><br><span class="line">        margin_square = K.square(K.maximum(margin - y_pred, <span class="number">0</span>))</span><br><span class="line">				</span><br><span class="line">				<span class="comment"># doing the mean is not strictly necessary as keras automatically does that</span></span><br><span class="line">				<span class="comment"># basically , we always need a scaler instead of tensor</span></span><br><span class="line">        <span class="keyword">return</span> K.mean(y_true * square_pred + (<span class="number">1</span> - y_true) * margin_square)</span><br><span class="line">    <span class="keyword">return</span> contrastive_loss</span><br></pre></td></tr></table></figure>

<h1 id="Custom-Layers"><a href="#Custom-Layers" class="headerlink" title="Custom Layers"></a>Custom Layers</h1><ul>
<li><p>way 1</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">  tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">  tf.keras.layers.Dense(<span class="number">128</span>),</span><br><span class="line">  tf.keras.layers.Lambda(<span class="keyword">lambda</span> x: tf.<span class="built_in">abs</span>(x)), </span><br><span class="line">  tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure></li>
<li><p>way 2</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_relu</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> K.maximum(-<span class="number">0.1</span>, x)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>),</span><br><span class="line">    tf.keras.layers.Lambda(my_relu), </span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Layers"><a href="#Layers" class="headerlink" title="Layers"></a>Layers</h2><p><img src="layers.png"></p>
<h2 id="Custom-Dense-Layer"><a href="#Custom-Dense-Layer" class="headerlink" title="Custom Dense Layer"></a>Custom Dense Layer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inherit from this base class</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Layer</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleDense</span>(<span class="params">Layer</span>):</span> <span class="comment"># inherit from keras Layer class</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units=<span class="number">32</span></span>):</span> <span class="comment"># initialization</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;Initializes the instance attributes&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>(SimpleDense, self).__init__()</span><br><span class="line">        self.units = units</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span> <span class="comment"># will run when instance is created</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;Create the state of the layer (weights)&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="comment"># initialize the weights</span></span><br><span class="line">        w_init = tf.random_normal_initializer()</span><br><span class="line">        self.w = tf.Variable(name=<span class="string">&quot;kernel&quot;</span>,</span><br><span class="line">            initial_value=w_init(shape=(input_shape[-<span class="number">1</span>], self.units),</span><br><span class="line">                                 dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">            trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># initialize the biases</span></span><br><span class="line">        b_init = tf.zeros_initializer()</span><br><span class="line">        self.b = tf.Variable(name=<span class="string">&quot;bias&quot;</span>,</span><br><span class="line">            initial_value=b_init(shape=(self.units,), dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">            trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span> <span class="comment"># performs computation and calls during training</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;Defines the computation from inputs to outputs&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="keyword">return</span> tf.matmul(inputs, self.w) + self.b <span class="comment">## WX+B</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># declare an instance of the class</span></span><br><span class="line">my_dense = SimpleDense(units=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define an input and feed into the layer</span></span><br><span class="line">x = tf.ones((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">y = my_dense(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># parameters of the base Layer class like `variables` can be used</span></span><br><span class="line"><span class="built_in">print</span>(my_dense.variables)</span><br></pre></td></tr></table></figure>

<h3 id="usage-1"><a href="#usage-1" class="headerlink" title="usage 1"></a>usage 1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define the dataset</span></span><br><span class="line">xs = np.array([-<span class="number">1.0</span>,  <span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line">ys = np.array([-<span class="number">3.0</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">3.0</span>, <span class="number">5.0</span>, <span class="number">7.0</span>], dtype=<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># use the Sequential API to build a model with our custom layer</span></span><br><span class="line">my_layer = SimpleDense(units=<span class="number">1</span>)</span><br><span class="line">model = tf.keras.Sequential([my_layer])</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure and train the model</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;sgd&#x27;</span>, loss=<span class="string">&#x27;mean_squared_error&#x27;</span>)</span><br><span class="line">model.fit(xs, ys, epochs=<span class="number">500</span>,verbose=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># perform inference</span></span><br><span class="line"><span class="built_in">print</span>(model.predict([<span class="number">10.0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># see the updated state of the variables</span></span><br><span class="line"><span class="built_in">print</span>(my_layer.variables)</span><br></pre></td></tr></table></figure>

<h3 id="usage-2"><a href="#usage-2" class="headerlink" title="usage 2"></a>usage 2</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_relu</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> K.maximum(-<span class="number">0.1</span>, x)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    SimpleDense(<span class="number">128</span>),</span><br><span class="line">    tf.keras.layers.Lambda(my_relu), </span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h2 id="Activating-Custom-Layer"><a href="#Activating-Custom-Layer" class="headerlink" title="Activating Custom Layer"></a>Activating Custom Layer</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SimpleDense</span>(<span class="params">Layer</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># add an activation parameter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units=<span class="number">32</span>, activation=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(SimpleDense, self).__init__()</span><br><span class="line">        self.units = units</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># define the activation to get from the built-in activation layers in Keras</span></span><br><span class="line">        self.activation = tf.keras.activations.get(activation)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        w_init = tf.random_normal_initializer()</span><br><span class="line">        self.w = tf.Variable(name=<span class="string">&quot;kernel&quot;</span>,</span><br><span class="line">            initial_value=w_init(shape=(input_shape[-<span class="number">1</span>], self.units),</span><br><span class="line">                                 dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">            trainable=<span class="literal">True</span>)</span><br><span class="line">        b_init = tf.zeros_initializer()</span><br><span class="line">        self.b = tf.Variable(name=<span class="string">&quot;bias&quot;</span>,</span><br><span class="line">            initial_value=b_init(shape=(self.units,), dtype=<span class="string">&#x27;float32&#x27;</span>),</span><br><span class="line">            trainable=<span class="literal">True</span>)</span><br><span class="line">        <span class="built_in">super</span>().build(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># pass the computation to the activation layer</span></span><br><span class="line">        <span class="keyword">return</span> self.activation(tf.matmul(inputs, self.w) + self.b)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line"></span><br><span class="line">(x_train, y_train),(x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>)),</span><br><span class="line">    SimpleDense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;sparse_categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, epochs=<span class="number">5</span>)</span><br><span class="line">model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<h1 id="Custom-Model"><a href="#Custom-Model" class="headerlink" title="Custom Model"></a>Custom Model</h1><p><img src="custom_model_1.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># define inputs</span></span><br><span class="line">input_a = Input(shape=[<span class="number">1</span>], name=<span class="string">&quot;Wide_Input&quot;</span>)</span><br><span class="line">input_b = Input(shape=[<span class="number">1</span>], name=<span class="string">&quot;Deep_Input&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define deep path</span></span><br><span class="line">hidden_1 = Dense(<span class="number">30</span>, activation=<span class="string">&quot;relu&quot;</span>)(input_b)</span><br><span class="line">hidden_2 = Dense(<span class="number">30</span>, activation=<span class="string">&quot;relu&quot;</span>)(hidden_1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define merged path</span></span><br><span class="line">concat = concatenate([input_a, hidden_2])</span><br><span class="line">output = Dense(<span class="number">1</span>, name=<span class="string">&quot;Output&quot;</span>)(concat)</span><br><span class="line"></span><br><span class="line"><span class="comment"># define another output for the deep path</span></span><br><span class="line">aux_output = Dense(<span class="number">1</span>,name=<span class="string">&quot;aux_Output&quot;</span>)(hidden_2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># build the model</span></span><br><span class="line">model = Model(inputs=[input_a, input_b], outputs=[output, aux_output])</span><br><span class="line"></span><br><span class="line"><span class="comment"># visualize the architecture</span></span><br><span class="line">plot_model(model)</span><br></pre></td></tr></table></figure>

<h2 id="Implement-As-Class"><a href="#Implement-As-Class" class="headerlink" title="Implement As Class"></a>Implement As Class</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># inherit from the Model base class</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WideAndDeepModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, units=<span class="number">30</span>, activation=<span class="string">&#x27;relu&#x27;</span>, **kwargs</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;initializes the instance attributes&#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(**kwargs)</span><br><span class="line">        self.hidden1 = Dense(units, activation=activation)</span><br><span class="line">        self.hidden2 = Dense(units, activation=activation)</span><br><span class="line">        self.main_output = Dense(<span class="number">1</span>)</span><br><span class="line">        self.aux_output = Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;defines the network architecture&#x27;&#x27;&#x27;</span></span><br><span class="line">        input_A, input_B = inputs</span><br><span class="line">        hidden1 = self.hidden1(input_B)</span><br><span class="line">        hidden2 = self.hidden2(hidden1)</span><br><span class="line">        concat = concatenate([input_A, hidden2])</span><br><span class="line">        main_output = self.main_output(concat)</span><br><span class="line">        aux_output = self.aux_output(hidden2)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> main_output, aux_output</span><br><span class="line"></span><br><span class="line"><span class="comment"># create an instance of the model</span></span><br><span class="line">model = WideAndDeepModel()</span><br></pre></td></tr></table></figure>

<h2 id="Model-Class"><a href="#Model-Class" class="headerlink" title="Model Class"></a>Model Class</h2><ul>
<li>Built-in training, evaluation, and prediction loops<ul>
<li><code>model.fit()</code> , <code>model.evaluate()</code> , <code>model.predict()</code></li>
</ul>
</li>
<li>Saving and serialization APIs<ul>
<li><code>model.save()</code> , <code>model.save_weights()</code></li>
</ul>
</li>
<li>Built-in training, evaluation, and prediction loops<ul>
<li><code>model.summary()</code> , <code>tf.keras.utils.plot_model()</code></li>
</ul>
</li>
</ul>
<h2 id="Benefits-of-subclassing-models"><a href="#Benefits-of-subclassing-models" class="headerlink" title="Benefits of subclassing models"></a>Benefits of subclassing models</h2><ul>
<li>Extends how you’ve been building models</li>
<li>Continue to use functional and sequential code</li>
<li>Modular architecture</li>
<li>Try out experiments quickly</li>
<li>Control flow in the network</li>
</ul>
<h2 id="Residual-Networks"><a href="#Residual-Networks" class="headerlink" title="Residual Networks"></a>Residual Networks</h2><p><img src="res_net_1.png"></p>
<p><img src="res_net_2.png"></p>
<p><img src="res_net_3.png"></p>
<p><img src="res_net_4.png"></p>
<p><img src="res_net_5.png"></p>
<p><img src="res_net_6.png"></p>
<h2 id="Implementing-Mini-Resnet"><a href="#Implementing-Mini-Resnet" class="headerlink" title="Implementing Mini Resnet"></a>Implementing Mini Resnet</h2><p><img src="mini_res_net_1.png"></p>
<p><img src="mini_res_net_2.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IdentityBlock</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filters, kernel_size</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(IdentityBlock, self).__init__(name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.conv1 = tf.keras.layers.Conv2D(filters, kernel_size, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn1 = tf.keras.layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        self.conv2 = tf.keras.layers.Conv2D(filters, kernel_size, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn2 = tf.keras.layers.BatchNormalization()</span><br><span class="line"></span><br><span class="line">        self.act = tf.keras.layers.Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.add = tf.keras.layers.Add()</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, input_tensor</span>):</span></span><br><span class="line">        x = self.conv1(input_tensor)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line"></span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.bn2(x)</span><br><span class="line"></span><br><span class="line">        x = self.add([x, input_tensor])</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p><img src="mini_res_net_3.png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes</span>):</span> <span class="comment"># generic resnet , so num_classes is a parameter</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.conv = tf.keras.layers.Conv2D(<span class="number">64</span>, <span class="number">7</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.bn = tf.keras.layers.BatchNormalization()</span><br><span class="line">        self.act = tf.keras.layers.Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.max_pool = tf.keras.layers.MaxPool2D((<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Use the Identity blocks that you just defined</span></span><br><span class="line">        self.id1a = IdentityBlock(<span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">        self.id1b = IdentityBlock(<span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">        self.global_pool = tf.keras.layers.GlobalAveragePooling2D()</span><br><span class="line">        self.classifier = tf.keras.layers.Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        x = self.conv(inputs)</span><br><span class="line">        x = self.bn(x)</span><br><span class="line">        x = self.act(x)</span><br><span class="line">        x = self.max_pool(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># insert the identity blocks in the middle of the network</span></span><br><span class="line">        x = self.id1a(x)</span><br><span class="line">        x = self.id1b(x)</span><br><span class="line"></span><br><span class="line">        x = self.global_pool(x)</span><br><span class="line">        <span class="keyword">return</span> self.classifier(x)</span><br></pre></td></tr></table></figure>
  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/mindcraft/">Home</a></li>
         
          <li><a href="/mindcraft/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Custom-Loss-Function"><span class="toc-number">1.</span> <span class="toc-text">Custom Loss Function</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Loss-Function-Template"><span class="toc-number">1.1.</span> <span class="toc-text">Custom Loss Function Template</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Huber-Loss"><span class="toc-number">1.2.</span> <span class="toc-text">Huber Loss</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Loss-Function-Hyper-Parameter-Tuning-using-wrapper-function"><span class="toc-number">1.3.</span> <span class="toc-text">Custom Loss Function Hyper Parameter Tuning (using wrapper function)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Loss-Function-using-classes"><span class="toc-number">1.4.</span> <span class="toc-text">Custom Loss Function using classes</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Contrastive-Loss-Function"><span class="toc-number">1.5.</span> <span class="toc-text">Contrastive Loss Function</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Custom-Layers"><span class="toc-number">2.</span> <span class="toc-text">Custom Layers</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Layers"><span class="toc-number">2.1.</span> <span class="toc-text">Layers</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Custom-Dense-Layer"><span class="toc-number">2.2.</span> <span class="toc-text">Custom Dense Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#usage-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">usage 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#usage-2"><span class="toc-number">2.2.2.</span> <span class="toc-text">usage 2</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Activating-Custom-Layer"><span class="toc-number">2.3.</span> <span class="toc-text">Activating Custom Layer</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Custom-Model"><span class="toc-number">3.</span> <span class="toc-text">Custom Model</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Implement-As-Class"><span class="toc-number">3.1.</span> <span class="toc-text">Implement As Class</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Model-Class"><span class="toc-number">3.2.</span> <span class="toc-text">Model Class</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Benefits-of-subclassing-models"><span class="toc-number">3.3.</span> <span class="toc-text">Benefits of subclassing models</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Residual-Networks"><span class="toc-number">3.4.</span> <span class="toc-text">Residual Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implementing-Mini-Resnet"><span class="toc-number">3.5.</span> <span class="toc-text">Implementing Mini Resnet</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&text=Tensorflow Advanced : Part 2"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&is_video=false&description=Tensorflow Advanced : Part 2"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Tensorflow Advanced : Part 2&body=Check out this article: https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&title=Tensorflow Advanced : Part 2"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&name=Tensorflow Advanced : Part 2&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://zarif98sjs.github.io/mindcraft/TF_Advanced_P2/&t=Tensorflow Advanced : Part 2"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2019-2021
    Md. Zarif Ul Alam
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/mindcraft/">Home</a></li>
         
          <li><a href="/mindcraft/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/mindcraft/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->


</body>
</html>
