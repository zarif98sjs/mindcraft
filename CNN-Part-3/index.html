<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Method 1 Part 2 : Feature Extraction with Data AugmentationOld Preprocessings1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined b">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN : Watching the world through Neural Networks - Part 3">
<meta property="og:url" content="https://zarif98sjs.github.io/mindcraft/CNN-Part-3/index.html">
<meta property="og:site_name" content="MindCraft">
<meta property="og:description" content="Method 1 Part 2 : Feature Extraction with Data AugmentationOld Preprocessings1234567891011121314151617# This Python 3 environment comes with many helpful analytics libraries installed# It is defined b">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/CNN-Part-3/output_34_0.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/CNN-Part-3/output_34_1.png">
<meta property="og:image" content="attachment:image.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/CNN-Part-3/output_50_0.png">
<meta property="og:image" content="https://zarif98sjs.github.io/mindcraft/CNN-Part-3/output_50_1.png">
<meta property="article:published_time" content="2020-07-01T00:00:00.000Z">
<meta property="article:modified_time" content="2021-04-27T07:44:30.519Z">
<meta property="article:author" content="Md. Zarif Ul Alam">
<meta property="article:tag" content="Algo, DS, Software &amp; What Not!">
<meta property="article:tag" content="Learning Notes">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zarif98sjs.github.io/mindcraft/CNN-Part-3/output_34_0.png">
    
    
      
        
          <link rel="shortcut icon" href="/mindcraft/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/mindcraft/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/mindcraft/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>CNN : Watching the world through Neural Networks - Part 3</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/mindcraft/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" "Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/mindcraft/">Home</a></li>
         
          <li><a href="/mindcraft/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post " href="/mindcraft/SingleSourceShortestPath/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post " href="/mindcraft/CNN-Part-2/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top " href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post " href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&text=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&is_video=false&description=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=CNN : Watching the world through Neural Networks - Part 3&body=Check out this article: https://zarif98sjs.github.io/mindcraft/CNN-Part-3/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&name=CNN : Watching the world through Neural Networks - Part 3&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&t=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Method-1-Part-2-Feature-Extraction-with-Data-Augmentation"><span class="toc-number">1.</span> <span class="toc-text">Method 1 Part 2 : Feature Extraction with Data Augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Old-Preprocessings"><span class="toc-number">1.1.</span> <span class="toc-text">Old Preprocessings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-1"><span class="toc-number">1.2.</span> <span class="toc-text">Important Note #1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-2"><span class="toc-number">1.3.</span> <span class="toc-text">Important Note #2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prediction"><span class="toc-number">1.4.</span> <span class="toc-text">Prediction</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method-2-Fine-Tuning"><span class="toc-number">2.</span> <span class="toc-text">Method #2 : Fine Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-1-1"><span class="toc-number">2.1.</span> <span class="toc-text">Important Note #1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-2-1"><span class="toc-number">2.2.</span> <span class="toc-text">Important Note #2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-3"><span class="toc-number">2.3.</span> <span class="toc-text">Important Note #3</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Conclusion"><span class="toc-number">3.</span> <span class="toc-text">Conclusion</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        CNN : Watching the world through Neural Networks - Part 3
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Md. Zarif Ul Alam</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-07-01T00:00:00.000Z" itemprop="datePublished">2020-07-01</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/mindcraft/categories/Machine-Learning/">Machine Learning</a> › <a class="category-link" href="/mindcraft/categories/Machine-Learning/Tensorflow/">Tensorflow</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/mindcraft/tags/Algo-DS-Software-What-Not/" rel="tag">Algo, DS, Software & What Not!</a>, <a class="tag-link-link" href="/mindcraft/tags/Learning-Notes/" rel="tag">Learning Notes</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Method-1-Part-2-Feature-Extraction-with-Data-Augmentation"><a href="#Method-1-Part-2-Feature-Extraction-with-Data-Augmentation" class="headerlink" title="Method 1 Part 2 : Feature Extraction with Data Augmentation"></a>Method 1 Part 2 : Feature Extraction with Data Augmentation</h1><h2 id="Old-Preprocessings"><a href="#Old-Preprocessings" class="headerlink" title="Old Preprocessings"></a>Old Preprocessings</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here&#x27;s several helpful packages to load</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the read-only &quot;../input/&quot; directory</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">&#x27;/kaggle/input&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        <span class="built_in">print</span>(os.path.join(dirname, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; </span></span><br><span class="line"><span class="comment"># You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current session</span></span><br></pre></td></tr></table></figure>

<pre><code>/kaggle/input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv
/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip
/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(<span class="string">&quot;../input/dogs-vs-cats-redux-kernels-edition/&quot;</span>+<span class="string">&quot;train&quot;</span>+<span class="string">&quot;.zip&quot;</span>,<span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> z:</span><br><span class="line">    z.extractall(<span class="string">&quot;.&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">with</span> zipfile.ZipFile(<span class="string">&quot;../input/dogs-vs-cats-redux-kernels-edition/&quot;</span>+<span class="string">&quot;test&quot;</span>+<span class="string">&quot;.zip&quot;</span>,<span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> z:</span><br><span class="line">    z.extractall(<span class="string">&quot;.&quot;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, cv2, re, random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> img_to_array, load_img</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers, models, optimizers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img_width = <span class="number">150</span></span><br><span class="line">img_height = <span class="number">150</span></span><br><span class="line">TRAIN_DIR = <span class="string">&#x27;/kaggle/working/train/&#x27;</span></span><br><span class="line">TEST_DIR = <span class="string">&#x27;/kaggle/working/test/&#x27;</span></span><br><span class="line">train_images_dogs_cats = [TRAIN_DIR+i <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(TRAIN_DIR)] <span class="comment"># use this for full dataset</span></span><br><span class="line">test_images_dogs_cats = [TEST_DIR+i <span class="keyword">for</span> i <span class="keyword">in</span> os.listdir(TEST_DIR)]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_images_dogs_cats))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(test_images_dogs_cats))</span><br></pre></td></tr></table></figure>

<pre><code>25000
12500
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">atoi</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">int</span>(text) <span class="keyword">if</span> text.isdigit() <span class="keyword">else</span> text</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">natural_keys</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> [ atoi(c) <span class="keyword">for</span> c <span class="keyword">in</span> re.split(<span class="string">&#x27;(\d+)&#x27;</span>, text) ]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_of_each_sample = <span class="number">1500</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_images_dogs_cats.sort(key=natural_keys)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_images_dogs_cats))</span><br></pre></td></tr></table></figure>

<pre><code>25000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_images_dogs_cats = train_images_dogs_cats[<span class="number">0</span>:num_of_each_sample] + train_images_dogs_cats[<span class="number">12500</span>:<span class="number">12500</span>+num_of_each_sample] </span><br><span class="line">test_images_dogs_cats.sort(key=natural_keys)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(train_images_dogs_cats))</span><br></pre></td></tr></table></figure>

<pre><code>3000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">prepare_data</span>(<span class="params">list_of_images</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Returns two arrays: </span></span><br><span class="line"><span class="string">        x is an array of resized images</span></span><br><span class="line"><span class="string">        y is an array of labels</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x = [] <span class="comment"># images as arrays</span></span><br><span class="line">    y = [] <span class="comment"># labels</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> image <span class="keyword">in</span> list_of_images:</span><br><span class="line">        x.append(cv2.resize(cv2.imread(image), (img_width,img_height), interpolation=cv2.INTER_CUBIC))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> list_of_images:</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;dog&#x27;</span> <span class="keyword">in</span> i:</span><br><span class="line">            y.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">elif</span> <span class="string">&#x27;cat&#x27;</span> <span class="keyword">in</span> i:</span><br><span class="line">            y.append(<span class="number">0</span>)</span><br><span class="line">        <span class="comment">#else:</span></span><br><span class="line">            <span class="comment">#print(&#x27;neither cat nor dog name present in images&#x27;)</span></span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X, Y = prepare_data(train_images_dogs_cats)</span><br><span class="line"><span class="built_in">print</span>(K.image_data_format())</span><br></pre></td></tr></table></figure>

<pre><code>channels_last
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># First split the data in two sets, 80% for training, 20% for Val/Test)</span></span><br><span class="line">X_train, X_val, Y_train, Y_val = train_test_split(X,Y, test_size=<span class="number">0.3333334</span>, random_state=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">nb_train_samples = <span class="built_in">len</span>(X_train)</span><br><span class="line">nb_validation_samples = <span class="built_in">len</span>(X_val)</span><br><span class="line">batch_size = <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(nb_train_samples)</span><br><span class="line"><span class="built_in">print</span>(nb_validation_samples)</span><br></pre></td></tr></table></figure>

<pre><code>1999
1001
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications <span class="keyword">import</span> VGG16</span><br><span class="line"></span><br><span class="line">conv_base = VGG16(weights=<span class="string">&#x27;imagenet&#x27;</span>,include_top=<span class="literal">False</span>,input_shape=(img_width, img_height, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>

<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5
58892288/58889256 [==============================] - 0s 0us/step
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 150, 150, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 14,714,688
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p><strong>Because models behave just like layers, you can add a model (like <code>conv_base</code>) to a Sequential model just like you would add a layer</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(conv_base)</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">256</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Functional)           (None, 4, 4, 512)         14714688  
_________________________________________________________________
flatten (Flatten)            (None, 8192)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               2097408   
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 257       
=================================================================
Total params: 16,812,353
Trainable params: 16,812,353
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<p><strong>As you can see, the convolutional base of VGG16 has 14,714,688 parameters, which is very large. The classifier you’re adding on top has 2 million parameters</strong></p>
<h2 id="Important-Note-1"><a href="#Important-Note-1" class="headerlink" title="Important Note #1"></a>Important Note #1</h2><p>Before compiling and training the model, it’s very important to <em>freeze</em> the convolutional base. Freezing a layer or set of layers means <em>preventing their weights from being updated during training</em>. If you don’t do this, then the representations that were previously learned by the convolutional base will be modified during training</p>
<p>Because the Dense layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;This is the number of trainable weights &#x27;</span></span><br><span class="line">      <span class="string">&#x27;before freezing the conv base:&#x27;</span>, <span class="built_in">len</span>(model.trainable_weights))</span><br></pre></td></tr></table></figure>

<pre><code>This is the number of trainable weights before freezing the conv base: 30
</code></pre>
<p><strong>In Keras, you <em>freeze</em> a network by setting its trainable attribute to <code>False</code> :</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_base.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;This is the number of trainable weights &#x27;</span></span><br><span class="line">      <span class="string">&#x27;after freezing the conv base:&#x27;</span>, <span class="built_in">len</span>(model.trainable_weights))</span><br></pre></td></tr></table></figure>

<pre><code>This is the number of trainable weights after freezing the conv base: 4
</code></pre>
<p>With this setup, only the weights from the two Dense layers that you added will be trained. That’s a total of four weight tensors: two per layer (the main weight matrix and the bias vector)</p>
<h2 id="Important-Note-2"><a href="#Important-Note-2" class="headerlink" title="Important Note #2"></a>Important Note #2</h2><p>Note that in order for these changes to take effect, you must first compile the model. If you ever modify weight trainability after compilation, you should then recompile the model, or these changes will be ignored</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">      rescale=<span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">      rotation_range=<span class="number">40</span>,</span><br><span class="line">      width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">      shear_range=<span class="number">0.2</span>,</span><br><span class="line">      zoom_range=<span class="number">0.2</span>,</span><br><span class="line">      horizontal_flip=<span class="literal">True</span>,</span><br><span class="line">      fill_mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Note that the validation data should not be augmented!</span></span><br><span class="line">test_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)</span><br><span class="line">validation_generator = test_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=optimizers.RMSprop(lr=<span class="number">2e-5</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">      train_generator,</span><br><span class="line">      steps_per_epoch=np.ceil(nb_train_samples/batch_size),</span><br><span class="line">      epochs=<span class="number">30</span>,</span><br><span class="line">      validation_data=validation_generator,</span><br><span class="line">      validation_steps=np.ceil(nb_validation_samples/batch_size))</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/30
100/100 [==============================] - 14s 136ms/step - loss: 0.5779 - acc: 0.7154 - val_loss: 0.4019 - val_acc: 0.8511
Epoch 2/30
100/100 [==============================] - 12s 123ms/step - loss: 0.4645 - acc: 0.7919 - val_loss: 0.3314 - val_acc: 0.8671
Epoch 3/30
100/100 [==============================] - 13s 128ms/step - loss: 0.4007 - acc: 0.8304 - val_loss: 0.2953 - val_acc: 0.8761
Epoch 4/30
100/100 [==============================] - 12s 123ms/step - loss: 0.3730 - acc: 0.8434 - val_loss: 0.2743 - val_acc: 0.8821
Epoch 5/30
100/100 [==============================] - 13s 126ms/step - loss: 0.3601 - acc: 0.8449 - val_loss: 0.2589 - val_acc: 0.8851
Epoch 6/30
100/100 [==============================] - 13s 131ms/step - loss: 0.3390 - acc: 0.8574 - val_loss: 0.2496 - val_acc: 0.8901
Epoch 7/30
100/100 [==============================] - 12s 123ms/step - loss: 0.3267 - acc: 0.8579 - val_loss: 0.2426 - val_acc: 0.8931
Epoch 8/30
100/100 [==============================] - 13s 127ms/step - loss: 0.3159 - acc: 0.8564 - val_loss: 0.2638 - val_acc: 0.8901
Epoch 9/30
100/100 [==============================] - 12s 120ms/step - loss: 0.3194 - acc: 0.8699 - val_loss: 0.2351 - val_acc: 0.8931
Epoch 10/30
100/100 [==============================] - 13s 129ms/step - loss: 0.3091 - acc: 0.8649 - val_loss: 0.2337 - val_acc: 0.9021
Epoch 11/30
100/100 [==============================] - 13s 127ms/step - loss: 0.3071 - acc: 0.8619 - val_loss: 0.2340 - val_acc: 0.9111
Epoch 12/30
100/100 [==============================] - 12s 125ms/step - loss: 0.3014 - acc: 0.8709 - val_loss: 0.2293 - val_acc: 0.9111
Epoch 13/30
100/100 [==============================] - 13s 126ms/step - loss: 0.2945 - acc: 0.8764 - val_loss: 0.2358 - val_acc: 0.9011
Epoch 14/30
100/100 [==============================] - 12s 120ms/step - loss: 0.2969 - acc: 0.8694 - val_loss: 0.2270 - val_acc: 0.9121
Epoch 15/30
100/100 [==============================] - 13s 130ms/step - loss: 0.2774 - acc: 0.8819 - val_loss: 0.2177 - val_acc: 0.9081
Epoch 16/30
100/100 [==============================] - 12s 124ms/step - loss: 0.3002 - acc: 0.8714 - val_loss: 0.2173 - val_acc: 0.9131
Epoch 17/30
100/100 [==============================] - 12s 125ms/step - loss: 0.2858 - acc: 0.8749 - val_loss: 0.2234 - val_acc: 0.9061
Epoch 18/30
100/100 [==============================] - 13s 129ms/step - loss: 0.2872 - acc: 0.8779 - val_loss: 0.2127 - val_acc: 0.9111
Epoch 19/30
100/100 [==============================] - 13s 128ms/step - loss: 0.2795 - acc: 0.8844 - val_loss: 0.2110 - val_acc: 0.9061
Epoch 20/30
100/100 [==============================] - 13s 132ms/step - loss: 0.2773 - acc: 0.8799 - val_loss: 0.2348 - val_acc: 0.9071
Epoch 21/30
100/100 [==============================] - 12s 123ms/step - loss: 0.2752 - acc: 0.8814 - val_loss: 0.2350 - val_acc: 0.9071
Epoch 22/30
100/100 [==============================] - 13s 128ms/step - loss: 0.2720 - acc: 0.8849 - val_loss: 0.2355 - val_acc: 0.9081
Epoch 23/30
100/100 [==============================] - 13s 128ms/step - loss: 0.2779 - acc: 0.8769 - val_loss: 0.2111 - val_acc: 0.9121
Epoch 24/30
100/100 [==============================] - 13s 131ms/step - loss: 0.2540 - acc: 0.8909 - val_loss: 0.2116 - val_acc: 0.9101
Epoch 25/30
100/100 [==============================] - 13s 129ms/step - loss: 0.2512 - acc: 0.8919 - val_loss: 0.2141 - val_acc: 0.9131
Epoch 26/30
100/100 [==============================] - 12s 122ms/step - loss: 0.2598 - acc: 0.8849 - val_loss: 0.2185 - val_acc: 0.9111
Epoch 27/30
100/100 [==============================] - 13s 128ms/step - loss: 0.2596 - acc: 0.8824 - val_loss: 0.2159 - val_acc: 0.9081
Epoch 28/30
100/100 [==============================] - 13s 127ms/step - loss: 0.2647 - acc: 0.8889 - val_loss: 0.2161 - val_acc: 0.9091
Epoch 29/30
100/100 [==============================] - 14s 135ms/step - loss: 0.2615 - acc: 0.8849 - val_loss: 0.2146 - val_acc: 0.9101
Epoch 30/30
100/100 [==============================] - 13s 129ms/step - loss: 0.2614 - acc: 0.8864 - val_loss: 0.2200 - val_acc: 0.9131
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">&#x27;dogsVScats_TL_VGG16_feature_extraction_with_augmentation.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_acc&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_34_0.png" alt="png"></p>
<p><img src="output_34_1.png" alt="png"></p>
<p><strong>Validation accuracy has increased to 91 % Better than all the methods used so far .</strong></p>
<h2 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(test_images_dogs_cats))</span><br><span class="line">X_test, Y_test = prepare_data(test_images_dogs_cats) <span class="comment">#Y_test in this case will be []</span></span><br></pre></td></tr></table></figure>

<pre><code>12500
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_generator = test_datagen.flow(np.array(X_test), batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">prediction_probabilities = model.predict_generator(test_generator, verbose=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(prediction_probabilities.shape)</span><br></pre></td></tr></table></figure>

<pre><code>625/625 [==============================] - 19s 31ms/step
(12500, 1)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">counter = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(test_images_dogs_cats) + <span class="number">1</span>)</span><br><span class="line">solution = pd.DataFrame(&#123;<span class="string">&quot;id&quot;</span>: counter, <span class="string">&quot;label&quot;</span>:<span class="built_in">list</span>(prediction_probabilities)&#125;)</span><br><span class="line">cols = [<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    solution[col] = solution[col].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">str</span>(x).lstrip(<span class="string">&#x27;[&#x27;</span>).rstrip(<span class="string">&#x27;]&#x27;</span>)).astype(<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">solution.to_csv(<span class="string">&quot;dogsVScats_TL_VGG16_feature_extraction_with_augmentation.csv&quot;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Method-2-Fine-Tuning"><a href="#Method-2-Fine-Tuning" class="headerlink" title="Method #2 : Fine Tuning"></a>Method #2 : Fine Tuning</h1><p>Fine-tuning consists of unfreezing a few of the top layers of a frozen model base used for feature extraction, and jointly training both the newly added part of the model (in this case, the fully connected classifier) and these top layers</p>
<p>This is called fine-tuning because it slightly adjusts the more abstract representations of the model being reused, in order to make them more relevant for the problem at hand</p>
<p><img src="attachment:image.png" alt="image.png"></p>
<h2 id="Important-Note-1-1"><a href="#Important-Note-1-1" class="headerlink" title="Important Note #1"></a>Important Note #1</h2><p>In the last method we had to freeze the convolutional base to be able to train the classifier on top . Otherwise , if it was not trained , the error signal propagating through the network during the training will be too large , and previously learned representaions will be destroyed .</p>
<p>For this very reason , in case of fine tuning we can only do this once we hace trained our classifier . Otherwise , it will just perform worse .</p>
<p><strong>So , here are the steps for fine tuning :</strong></p>
<ul>
<li>Add your custom network on top of an already-trained base network</li>
<li>Freeze the base network</li>
<li>Train the part you added</li>
<li>Unfreeze some layers in the base network</li>
<li>Jointly train both these layers and the part you added</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_base.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;vgg16&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 150, 150, 3)]     0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         
=================================================================
Total params: 14,714,688
Trainable params: 0
Non-trainable params: 14,714,688
_________________________________________________________________
</code></pre>
<p>Let’s fine-tune the last three convolutional layers, which means all layers up to block4_pool should be frozen</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">conv_base.trainable = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">set_trainable = <span class="literal">False</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> conv_base.layers:</span><br><span class="line">    <span class="keyword">if</span> layer.name == <span class="string">&#x27;block5_conv1&#x27;</span>:</span><br><span class="line">        set_trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> set_trainable:</span><br><span class="line">        layer.trainable = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        layer.trainable = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h2 id="Important-Note-2-1"><a href="#Important-Note-2-1" class="headerlink" title="Important Note #2"></a>Important Note #2</h2><p><strong>Why not fine-tune more layers? Why not fine-tune the entire convolutional base? You could. But you need to consider the following :</strong></p>
<ul>
<li><p>Earlier layers in the convolutional base encode more-generic, reusable features, whereas layers higher up encode more-specialized features. It’s more useful to fine-tune the more specialized features, because these are the ones that need to be repurposed on your new problem</p>
</li>
<li><p>The more parameters you’re training, the more you’re at risk of overfitting. The convolutional base has 15 million parameters, so it would be risky to attempt to train it on your small dataset</p>
</li>
</ul>
<h2 id="Important-Note-3"><a href="#Important-Note-3" class="headerlink" title="Important Note #3"></a>Important Note #3</h2><p>The learning rate is low , The reason for using a low learning rate is that you want to limit the magnitude of the modifications you make to the representations of the three layers you’re fine-tuning . Updates that are too large may harm these representations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=optimizers.RMSprop(lr=<span class="number">1e-5</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;acc&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">      train_generator,</span><br><span class="line">      steps_per_epoch=np.ceil(nb_train_samples/batch_size),</span><br><span class="line">      epochs=<span class="number">100</span>,</span><br><span class="line">      validation_data=validation_generator,</span><br><span class="line">      validation_steps=np.ceil(nb_validation_samples/batch_size))</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/100
100/100 [==============================] - 14s 138ms/step - loss: 0.2615 - acc: 0.8829 - val_loss: 0.1953 - val_acc: 0.9241
Epoch 2/100
100/100 [==============================] - 14s 135ms/step - loss: 0.2437 - acc: 0.8934 - val_loss: 0.1982 - val_acc: 0.9211
Epoch 3/100
100/100 [==============================] - 13s 133ms/step - loss: 0.2166 - acc: 0.9070 - val_loss: 0.2319 - val_acc: 0.9141
Epoch 4/100
100/100 [==============================] - 13s 133ms/step - loss: 0.1874 - acc: 0.9230 - val_loss: 0.1771 - val_acc: 0.9411
Epoch 5/100
100/100 [==============================] - 14s 142ms/step - loss: 0.1786 - acc: 0.9315 - val_loss: 0.1757 - val_acc: 0.9321
Epoch 6/100
100/100 [==============================] - 14s 142ms/step - loss: 0.1726 - acc: 0.9255 - val_loss: 0.1681 - val_acc: 0.9341
Epoch 7/100
100/100 [==============================] - 14s 141ms/step - loss: 0.1521 - acc: 0.9405 - val_loss: 0.1860 - val_acc: 0.9341
Epoch 8/100
100/100 [==============================] - 14s 137ms/step - loss: 0.1547 - acc: 0.9345 - val_loss: 0.1663 - val_acc: 0.9441
Epoch 9/100
100/100 [==============================] - 13s 127ms/step - loss: 0.1348 - acc: 0.9460 - val_loss: 0.1657 - val_acc: 0.9471
Epoch 10/100
100/100 [==============================] - 14s 138ms/step - loss: 0.1231 - acc: 0.9460 - val_loss: 0.1791 - val_acc: 0.9391
Epoch 11/100
100/100 [==============================] - 13s 135ms/step - loss: 0.1217 - acc: 0.9490 - val_loss: 0.1880 - val_acc: 0.9381
Epoch 12/100
100/100 [==============================] - 14s 136ms/step - loss: 0.1243 - acc: 0.9480 - val_loss: 0.2026 - val_acc: 0.9431
Epoch 13/100
100/100 [==============================] - 14s 136ms/step - loss: 0.1095 - acc: 0.9600 - val_loss: 0.2083 - val_acc: 0.9391
Epoch 14/100
100/100 [==============================] - 13s 135ms/step - loss: 0.1100 - acc: 0.9550 - val_loss: 0.2353 - val_acc: 0.9391
Epoch 15/100
100/100 [==============================] - 14s 139ms/step - loss: 0.0931 - acc: 0.9625 - val_loss: 0.2113 - val_acc: 0.9401
Epoch 16/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0962 - acc: 0.9645 - val_loss: 0.2170 - val_acc: 0.9471
Epoch 17/100
100/100 [==============================] - 14s 143ms/step - loss: 0.0939 - acc: 0.9625 - val_loss: 0.1793 - val_acc: 0.9461
Epoch 18/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0913 - acc: 0.9645 - val_loss: 0.1815 - val_acc: 0.9371
Epoch 19/100
100/100 [==============================] - 14s 144ms/step - loss: 0.1001 - acc: 0.9660 - val_loss: 0.1970 - val_acc: 0.9411
Epoch 20/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0873 - acc: 0.9685 - val_loss: 0.2059 - val_acc: 0.9471
Epoch 21/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0830 - acc: 0.9645 - val_loss: 0.1975 - val_acc: 0.9371
Epoch 22/100
100/100 [==============================] - 14s 143ms/step - loss: 0.0671 - acc: 0.9735 - val_loss: 0.2329 - val_acc: 0.9431
Epoch 23/100
100/100 [==============================] - 13s 127ms/step - loss: 0.0768 - acc: 0.9715 - val_loss: 0.2145 - val_acc: 0.9431
Epoch 24/100
100/100 [==============================] - 14s 145ms/step - loss: 0.0711 - acc: 0.9740 - val_loss: 0.2449 - val_acc: 0.9411
Epoch 25/100
100/100 [==============================] - 13s 134ms/step - loss: 0.0731 - acc: 0.9715 - val_loss: 0.1994 - val_acc: 0.9491
Epoch 26/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0693 - acc: 0.9715 - val_loss: 0.2058 - val_acc: 0.9421
Epoch 27/100
100/100 [==============================] - 13s 131ms/step - loss: 0.0603 - acc: 0.9740 - val_loss: 0.2730 - val_acc: 0.9381
Epoch 28/100
100/100 [==============================] - 13s 134ms/step - loss: 0.0588 - acc: 0.9775 - val_loss: 0.2298 - val_acc: 0.9431
Epoch 29/100
100/100 [==============================] - 14s 143ms/step - loss: 0.0554 - acc: 0.9800 - val_loss: 0.2269 - val_acc: 0.9431
Epoch 30/100
100/100 [==============================] - 13s 128ms/step - loss: 0.0544 - acc: 0.9840 - val_loss: 0.2258 - val_acc: 0.9461
Epoch 31/100
100/100 [==============================] - 14s 139ms/step - loss: 0.0647 - acc: 0.9770 - val_loss: 0.2610 - val_acc: 0.9431
Epoch 32/100
100/100 [==============================] - 14s 138ms/step - loss: 0.0556 - acc: 0.9800 - val_loss: 0.2369 - val_acc: 0.9441
Epoch 33/100
100/100 [==============================] - 13s 128ms/step - loss: 0.0579 - acc: 0.9765 - val_loss: 0.1951 - val_acc: 0.9451
Epoch 34/100
100/100 [==============================] - 15s 146ms/step - loss: 0.0579 - acc: 0.9815 - val_loss: 0.2730 - val_acc: 0.9411
Epoch 35/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0468 - acc: 0.9815 - val_loss: 0.2663 - val_acc: 0.9441
Epoch 36/100
100/100 [==============================] - 14s 143ms/step - loss: 0.0489 - acc: 0.9785 - val_loss: 0.3169 - val_acc: 0.9371
Epoch 37/100
100/100 [==============================] - 13s 134ms/step - loss: 0.0426 - acc: 0.9820 - val_loss: 0.2252 - val_acc: 0.9461
Epoch 38/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0400 - acc: 0.9870 - val_loss: 0.2132 - val_acc: 0.9401
Epoch 39/100
100/100 [==============================] - 15s 146ms/step - loss: 0.0483 - acc: 0.9815 - val_loss: 0.2177 - val_acc: 0.9481
Epoch 40/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0354 - acc: 0.9870 - val_loss: 0.2308 - val_acc: 0.9481
Epoch 41/100
100/100 [==============================] - 16s 161ms/step - loss: 0.0501 - acc: 0.9790 - val_loss: 0.2245 - val_acc: 0.9401
Epoch 42/100
100/100 [==============================] - 13s 127ms/step - loss: 0.0378 - acc: 0.9845 - val_loss: 0.2299 - val_acc: 0.9401
Epoch 43/100
100/100 [==============================] - 13s 127ms/step - loss: 0.0552 - acc: 0.9810 - val_loss: 0.3002 - val_acc: 0.9421
Epoch 44/100
100/100 [==============================] - 14s 144ms/step - loss: 0.0410 - acc: 0.9860 - val_loss: 0.2625 - val_acc: 0.9461
Epoch 45/100
100/100 [==============================] - 13s 130ms/step - loss: 0.0400 - acc: 0.9845 - val_loss: 0.2478 - val_acc: 0.9500
Epoch 46/100
100/100 [==============================] - 15s 154ms/step - loss: 0.0290 - acc: 0.9880 - val_loss: 0.2920 - val_acc: 0.9431
Epoch 47/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0320 - acc: 0.9885 - val_loss: 0.2870 - val_acc: 0.9461
Epoch 48/100
100/100 [==============================] - 13s 133ms/step - loss: 0.0376 - acc: 0.9865 - val_loss: 0.2460 - val_acc: 0.9481
Epoch 49/100
100/100 [==============================] - 15s 147ms/step - loss: 0.0402 - acc: 0.9875 - val_loss: 0.2469 - val_acc: 0.9500
Epoch 50/100
100/100 [==============================] - 14s 139ms/step - loss: 0.0291 - acc: 0.9870 - val_loss: 0.2454 - val_acc: 0.9540
Epoch 51/100
100/100 [==============================] - 14s 144ms/step - loss: 0.0434 - acc: 0.9885 - val_loss: 0.2663 - val_acc: 0.9451
Epoch 52/100
100/100 [==============================] - 13s 129ms/step - loss: 0.0404 - acc: 0.9875 - val_loss: 0.2841 - val_acc: 0.9431
Epoch 53/100
100/100 [==============================] - 13s 133ms/step - loss: 0.0355 - acc: 0.9860 - val_loss: 0.2313 - val_acc: 0.9520
Epoch 54/100
100/100 [==============================] - 15s 151ms/step - loss: 0.0365 - acc: 0.9850 - val_loss: 0.2947 - val_acc: 0.9371
Epoch 55/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0326 - acc: 0.9880 - val_loss: 0.2370 - val_acc: 0.9451
Epoch 56/100
100/100 [==============================] - 15s 147ms/step - loss: 0.0278 - acc: 0.9910 - val_loss: 0.2252 - val_acc: 0.9491
Epoch 57/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0305 - acc: 0.9885 - val_loss: 0.2394 - val_acc: 0.9441
Epoch 58/100
100/100 [==============================] - 13s 129ms/step - loss: 0.0283 - acc: 0.9905 - val_loss: 0.2625 - val_acc: 0.9411
Epoch 59/100
100/100 [==============================] - 15s 153ms/step - loss: 0.0252 - acc: 0.9925 - val_loss: 0.4189 - val_acc: 0.9291
Epoch 60/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0276 - acc: 0.9880 - val_loss: 0.3043 - val_acc: 0.9391
Epoch 61/100
100/100 [==============================] - 15s 145ms/step - loss: 0.0199 - acc: 0.9925 - val_loss: 0.2874 - val_acc: 0.9381
Epoch 62/100
100/100 [==============================] - 13s 133ms/step - loss: 0.0342 - acc: 0.9900 - val_loss: 0.2599 - val_acc: 0.9491
Epoch 63/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0297 - acc: 0.9900 - val_loss: 0.2643 - val_acc: 0.9451
Epoch 64/100
100/100 [==============================] - 15s 154ms/step - loss: 0.0266 - acc: 0.9900 - val_loss: 0.2503 - val_acc: 0.9520
Epoch 65/100
100/100 [==============================] - 13s 127ms/step - loss: 0.0173 - acc: 0.9945 - val_loss: 0.2859 - val_acc: 0.9461
Epoch 66/100
100/100 [==============================] - 15s 151ms/step - loss: 0.0285 - acc: 0.9900 - val_loss: 0.2613 - val_acc: 0.9500
Epoch 67/100
100/100 [==============================] - 13s 135ms/step - loss: 0.0151 - acc: 0.9965 - val_loss: 0.4303 - val_acc: 0.9381
Epoch 68/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0217 - acc: 0.9910 - val_loss: 0.3756 - val_acc: 0.9401
Epoch 69/100
100/100 [==============================] - 15s 154ms/step - loss: 0.0237 - acc: 0.9905 - val_loss: 0.3687 - val_acc: 0.9371
Epoch 70/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0329 - acc: 0.9865 - val_loss: 0.2500 - val_acc: 0.9471
Epoch 71/100
100/100 [==============================] - 17s 168ms/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.2839 - val_acc: 0.9471
Epoch 72/100
100/100 [==============================] - 13s 127ms/step - loss: 0.0278 - acc: 0.9920 - val_loss: 0.2722 - val_acc: 0.9500
Epoch 73/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0148 - acc: 0.9940 - val_loss: 0.3094 - val_acc: 0.9471
Epoch 74/100
100/100 [==============================] - 16s 156ms/step - loss: 0.0166 - acc: 0.9945 - val_loss: 0.3381 - val_acc: 0.9421
Epoch 75/100
100/100 [==============================] - 13s 135ms/step - loss: 0.0327 - acc: 0.9905 - val_loss: 0.2523 - val_acc: 0.9431
Epoch 76/100
100/100 [==============================] - 15s 152ms/step - loss: 0.0199 - acc: 0.9915 - val_loss: 0.2700 - val_acc: 0.9500
Epoch 77/100
100/100 [==============================] - 13s 129ms/step - loss: 0.0199 - acc: 0.9915 - val_loss: 0.3265 - val_acc: 0.9351
Epoch 78/100
100/100 [==============================] - 13s 131ms/step - loss: 0.0228 - acc: 0.9935 - val_loss: 0.2877 - val_acc: 0.9491
Epoch 79/100
100/100 [==============================] - 15s 153ms/step - loss: 0.0225 - acc: 0.9930 - val_loss: 0.3320 - val_acc: 0.9510
Epoch 80/100
100/100 [==============================] - 13s 135ms/step - loss: 0.0237 - acc: 0.9930 - val_loss: 0.3621 - val_acc: 0.9421
Epoch 81/100
100/100 [==============================] - 15s 155ms/step - loss: 0.0228 - acc: 0.9905 - val_loss: 0.3725 - val_acc: 0.9411
Epoch 82/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0214 - acc: 0.9915 - val_loss: 0.2836 - val_acc: 0.9441
Epoch 83/100
100/100 [==============================] - 13s 127ms/step - loss: 0.0251 - acc: 0.9890 - val_loss: 0.2938 - val_acc: 0.9431
Epoch 84/100
100/100 [==============================] - 17s 165ms/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.3017 - val_acc: 0.9441
Epoch 85/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0233 - acc: 0.9935 - val_loss: 0.2861 - val_acc: 0.9431
Epoch 86/100
100/100 [==============================] - 14s 137ms/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.3171 - val_acc: 0.9451
Epoch 87/100
100/100 [==============================] - 14s 140ms/step - loss: 0.0200 - acc: 0.9915 - val_loss: 0.2677 - val_acc: 0.9471
Epoch 88/100
100/100 [==============================] - 14s 137ms/step - loss: 0.0164 - acc: 0.9950 - val_loss: 0.4077 - val_acc: 0.9311
Epoch 89/100
100/100 [==============================] - 16s 161ms/step - loss: 0.0153 - acc: 0.9955 - val_loss: 0.3073 - val_acc: 0.9441
Epoch 90/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0154 - acc: 0.9945 - val_loss: 0.3021 - val_acc: 0.9471
Epoch 91/100
100/100 [==============================] - 13s 128ms/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.3162 - val_acc: 0.9540
Epoch 92/100
100/100 [==============================] - 17s 169ms/step - loss: 0.0209 - acc: 0.9945 - val_loss: 0.3145 - val_acc: 0.9451
Epoch 93/100
100/100 [==============================] - 13s 130ms/step - loss: 0.0078 - acc: 0.9970 - val_loss: 0.4144 - val_acc: 0.9461
Epoch 94/100
100/100 [==============================] - 16s 161ms/step - loss: 0.0156 - acc: 0.9945 - val_loss: 0.3756 - val_acc: 0.9371
Epoch 95/100
100/100 [==============================] - 13s 125ms/step - loss: 0.0165 - acc: 0.9935 - val_loss: 0.3120 - val_acc: 0.9471
Epoch 96/100
100/100 [==============================] - 14s 141ms/step - loss: 0.0172 - acc: 0.9945 - val_loss: 0.2879 - val_acc: 0.9530
Epoch 97/100
100/100 [==============================] - 16s 161ms/step - loss: 0.0176 - acc: 0.9930 - val_loss: 0.2906 - val_acc: 0.9510
Epoch 98/100
100/100 [==============================] - 13s 132ms/step - loss: 0.0167 - acc: 0.9960 - val_loss: 0.3181 - val_acc: 0.9481
Epoch 99/100
100/100 [==============================] - 13s 126ms/step - loss: 0.0131 - acc: 0.9950 - val_loss: 0.3413 - val_acc: 0.9451
Epoch 100/100
100/100 [==============================] - 12s 125ms/step - loss: 0.0133 - acc: 0.9960 - val_loss: 0.3704 - val_acc: 0.9431
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">&#x27;dogsVScats_TL_VGG16_fine_tuning.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_acc&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">epochs = <span class="built_in">range</span>(<span class="built_in">len</span>(acc))</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_50_0.png" alt="png"></p>
<p><img src="output_50_1.png" alt="png"></p>
<p>Validation accuracy has increased to 95% . The best so far ! </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(test_images_dogs_cats))</span><br><span class="line">X_test, Y_test = prepare_data(test_images_dogs_cats) <span class="comment">#Y_test in this case will be []</span></span><br></pre></td></tr></table></figure>

<pre><code>12500
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_generator = test_datagen.flow(np.array(X_test), batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">prediction_probabilities = model.predict_generator(test_generator, verbose=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(prediction_probabilities.shape)</span><br></pre></td></tr></table></figure>

<pre><code>625/625 [==============================] - 19s 31ms/step
(12500, 1)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">counter = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(test_images_dogs_cats) + <span class="number">1</span>)</span><br><span class="line">solution = pd.DataFrame(&#123;<span class="string">&quot;id&quot;</span>: counter, <span class="string">&quot;label&quot;</span>:<span class="built_in">list</span>(prediction_probabilities)&#125;)</span><br><span class="line">cols = [<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">    solution[col] = solution[col].<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">str</span>(x).lstrip(<span class="string">&#x27;[&#x27;</span>).rstrip(<span class="string">&#x27;]&#x27;</span>)).astype(<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">solution.to_csv(<span class="string">&quot;dogsVScats_TL_VGG16_fine_tuning.csv&quot;</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><ul>
<li>Convnets are the best type of machine-learning models for computer-vision tasks. It’s possible to train one from scratch even on a very small dataset, with decent results.</li>
<li>On a small dataset, <strong>overfitting</strong> will be the main issue. <strong>Data augmentation</strong> is a powerful way to fight overfitting when you’re working with image data.</li>
<li>It’s easy to reuse an existing convnet on a new dataset via <strong>feature extraction</strong>. This is a valuable technique for working with small image datasets.</li>
<li>As a complement to feature extraction, you can use <strong>fine-tuning</strong>, which adapts to a new problem some of the representations previously learned by an existing model. This pushes performance a bit further</li>
</ul>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/mindcraft/">Home</a></li>
         
          <li><a href="/mindcraft/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Method-1-Part-2-Feature-Extraction-with-Data-Augmentation"><span class="toc-number">1.</span> <span class="toc-text">Method 1 Part 2 : Feature Extraction with Data Augmentation</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Old-Preprocessings"><span class="toc-number">1.1.</span> <span class="toc-text">Old Preprocessings</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-1"><span class="toc-number">1.2.</span> <span class="toc-text">Important Note #1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-2"><span class="toc-number">1.3.</span> <span class="toc-text">Important Note #2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prediction"><span class="toc-number">1.4.</span> <span class="toc-text">Prediction</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method-2-Fine-Tuning"><span class="toc-number">2.</span> <span class="toc-text">Method #2 : Fine Tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-1-1"><span class="toc-number">2.1.</span> <span class="toc-text">Important Note #1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-2-1"><span class="toc-number">2.2.</span> <span class="toc-text">Important Note #2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Important-Note-3"><span class="toc-number">2.3.</span> <span class="toc-text">Important Note #3</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Conclusion"><span class="toc-number">3.</span> <span class="toc-text">Conclusion</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&text=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&is_video=false&description=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=CNN : Watching the world through Neural Networks - Part 3&body=Check out this article: https://zarif98sjs.github.io/mindcraft/CNN-Part-3/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&title=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&name=CNN : Watching the world through Neural Networks - Part 3&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://zarif98sjs.github.io/mindcraft/CNN-Part-3/&t=CNN : Watching the world through Neural Networks - Part 3"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <!-- <a target="_blank" rel="noopener" href="https://hits.seeyoufarm.com"><img src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fzarif98sjs.github.io%2Fmindcraft%2F&count_bg=%2379C83D&title_bg=%23555555&icon=&icon_color=%23E7E7E7&title=hits&edge_flat=false"/></a> -->
  <div class="footer-left">
    Copyright &copy;
    
    
    2018-2021
    Md. Zarif Ul Alam
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/mindcraft/">Home</a></li>
         
          <li><a href="/mindcraft/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/mindcraft/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->


</body>
</html>
