<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="Supervised Learning : Binary Classification prepare train data define train variables define step&#x2F;update function define loss function   train  Importing Dependencies123456import numpy as npimport mat">
<meta property="og:type" content="article">
<meta property="og:title" content="MindCraft">
<meta property="og:url" content="https://zarif98sjs.github.io/dummy/BinaryClassification/index.html">
<meta property="og:site_name" content="MindCraft">
<meta property="og:description" content="Supervised Learning : Binary Classification prepare train data define train variables define step&#x2F;update function define loss function   train  Importing Dependencies123456import numpy as npimport mat">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://zarif98sjs.github.io/dummy/BinaryClassification/output_27_0.png">
<meta property="og:image" content="https://zarif98sjs.github.io/dummy/BinaryClassification/output_28_0.png">
<meta property="article:published_time" content="2021-04-27T06:01:06.799Z">
<meta property="article:modified_time" content="2020-12-23T15:26:52.000Z">
<meta property="article:author" content="Md. Zarif Ul Alam">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://zarif98sjs.github.io/dummy/BinaryClassification/output_27_0.png">
    
    
      
        
          <link rel="shortcut icon" href="/dummy/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/dummy/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/dummy/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>MindCraft</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/dummy/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 5.4.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" "Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/dummy/">Home</a></li>
         
          <li><a href="/dummy/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post " href="/dummy/MulticlassClassification/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post " href="/dummy/CNN-Part-3/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top " href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post " href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://zarif98sjs.github.io/dummy/BinaryClassification/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&text="><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&is_video=false&description="><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=&body=Check out this article: https://zarif98sjs.github.io/dummy/BinaryClassification/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&name=&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://zarif98sjs.github.io/dummy/BinaryClassification/&t="><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Supervised-Learning-Binary-Classification"><span class="toc-number">1.</span> <span class="toc-text">Supervised Learning : Binary Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Importing-Dependencies"><span class="toc-number">1.1.</span> <span class="toc-text">Importing Dependencies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Importing-Dataset"><span class="toc-number">1.2.</span> <span class="toc-text">Importing Dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Preparing-the-data"><span class="toc-number">1.3.</span> <span class="toc-text">Preparing the data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Building-the-neural-network"><span class="toc-number">1.4.</span> <span class="toc-text">Building the neural network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Architecture"><span class="toc-number">1.4.1.</span> <span class="toc-text">Architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Compile"><span class="toc-number">1.4.2.</span> <span class="toc-text">Compile</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Validation"><span class="toc-number">1.5.</span> <span class="toc-text">Validation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Train-Fit"><span class="toc-number">1.6.</span> <span class="toc-text">Train &#x2F; Fit</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluate"><span class="toc-number">1.7.</span> <span class="toc-text">Evaluate</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Avoiding-Overfitting"><span class="toc-number">1.8.</span> <span class="toc-text">Avoiding Overfitting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prediction"><span class="toc-number">1.9.</span> <span class="toc-text">Prediction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K-Fold-Cross-Validation"><span class="toc-number">1.10.</span> <span class="toc-text">K Fold Cross Validation</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Md. Zarif Ul Alam</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-04-27T06:01:06.799Z" itemprop="datePublished">2021-04-27</time>
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h1 id="Supervised-Learning-Binary-Classification"><a href="#Supervised-Learning-Binary-Classification" class="headerlink" title="Supervised Learning : Binary Classification"></a>Supervised Learning : Binary Classification</h1><ul>
<li><strong>prepare train data</strong></li>
<li><strong>define train variables</strong></li>
<li><strong>define step/update function</strong><ul>
<li><strong>define loss function</strong></li>
</ul>
</li>
<li><strong>train</strong></li>
</ul>
<h2 id="Importing-Dependencies"><a href="#Importing-Dependencies" class="headerlink" title="Importing Dependencies"></a>Importing Dependencies</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> models, layers, optimizers, losses, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.datasets <span class="keyword">import</span> imdb</span><br></pre></td></tr></table></figure>

<h2 id="Importing-Dataset"><a href="#Importing-Dataset" class="headerlink" title="Importing Dataset"></a>Importing Dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">LIMIT_WORD = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=LIMIT_WORD)</span><br></pre></td></tr></table></figure>

<pre><code>D:\Anaconda3\envs\tf_env\lib\site-packages\tensorflow_core\python\keras\datasets\imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
D:\Anaconda3\envs\tf_env\lib\site-packages\tensorflow_core\python\keras\datasets\imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify &#39;dtype=object&#39; when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_data[<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(train_labels[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]
1
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_to_english</span>(<span class="params">sequence</span>):</span></span><br><span class="line">    <span class="comment"># word_index is a dictionary mapping words to an integer index</span></span><br><span class="line">    word_index = imdb.get_word_index()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We reverse it, mapping integer indices to words</span></span><br><span class="line">    reverse_word_index = <span class="built_in">dict</span>(</span><br><span class="line">        [(value, key) <span class="keyword">for</span> (key, value) <span class="keyword">in</span> word_index.items()]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># We decode the review; note that our indices were offset by 3</span></span><br><span class="line">    <span class="comment"># because 0, 1 and 2 are reserved indices for &quot;padding&quot;, &quot;start of sequence&quot;, and &quot;unknown&quot;.</span></span><br><span class="line">    decoded_review = <span class="string">&quot; &quot;</span>.join(</span><br><span class="line">        [reverse_word_index.get(i - <span class="number">3</span>, <span class="string">&#x27;?&#x27;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> sequence] <span class="comment">## if not found replace with &#x27;?&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> decoded_review</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(convert_to_english(train_data[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>? this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy&#39;s that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all
</code></pre>
<h2 id="Preparing-the-data"><a href="#Preparing-the-data" class="headerlink" title="Preparing the data"></a>Preparing the data</h2><p>We cannot feed lists of integers into a neural network. We have to turn our lists into tensors. There are two ways we could do that:</p>
<ul>
<li>We could pad our lists so that they all have the same length, and turn them into an integer tensor of shape (samples, word_indices), then use as first layer in our network a layer capable of handling such integer tensors (the Embedding layer, which we will cover in detail later in the book).</li>
<li>We could one-hot-encode our lists to turn them into vectors of 0s and 1s. Concretely, this would mean for instance turning the sequence [3, 5] into a 10,000-dimensional vector that would be all-zeros except for indices 3 and 5, which would be ones. Then we could use as first layer in our network a Dense layer, capable of handling floating point vector data.</li>
</ul>
<p>We will go with the latter solution. Let’s vectorize our data, which we will do manually for maximum clarity:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## one hot encoding</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vectorize_sequences</span>(<span class="params">sequences, dimension=LIMIT_WORD</span>):</span></span><br><span class="line">    results = np.zeros((<span class="built_in">len</span>(sequences), dimension)) <span class="comment"># Create an all-zero matrix of shape (len(sequences), dimension)</span></span><br><span class="line">    <span class="keyword">for</span> i, sequence <span class="keyword">in</span> <span class="built_in">enumerate</span>(sequences):</span><br><span class="line">        results[i, sequence] = <span class="number">1</span> <span class="comment"># set specific indices of results[i] to 1s</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## vectorize train test data</span></span><br><span class="line">x_train = vectorize_sequences(train_data)</span><br><span class="line">x_test = vectorize_sequences(test_data)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x_train[<span class="number">0</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[0. 1. 1. ... 0. 0. 0.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## vectorize train test labels</span></span><br><span class="line">y_train = np.asarray(train_labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">y_test = np.asarray(test_labels).astype(<span class="string">&#x27;float32&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(y_train[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>1.0
</code></pre>
<h2 id="Building-the-neural-network"><a href="#Building-the-neural-network" class="headerlink" title="Building the neural network"></a>Building the neural network</h2><h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><ul>
<li><strong>Intermediate Dense Layer : 2 , Hidden Units : 16 , Activation : Relu</strong></li>
<li><strong>Output Layer : 1 , Activation : Sigmoid</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(LIMIT_WORD,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="Compile"><a href="#Compile" class="headerlink" title="Compile"></a>Compile</h3><p><strong>Lastly, we need to pick a loss function and an optimizer.<br>Since we are facing a binary classification problem and the output of our network is a<br>probability (we end our network with a single-unit layer with a sigmoid activation),<br>is it best to use the binary_crossentropy loss.<br>It isn’t the only viable choice: you could use, for instance, mean_squared_error.<br>But <em>crossentropy is usually the best choice when you are dealing with models that output<br>probabilities</em>. Crossentropy is a quantity from the field of Information Theory,<br>that measures the “distance” between probability distributions, or in our case, between<br>the ground-truth distribution and our predictions.</strong></p>
<ul>
<li><strong>Loss Function : Binary Crossentropy</strong></li>
<li><strong>Optimizer : rmsprop</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">    loss=losses.binary_crossentropy,</span><br><span class="line">    metrics=[metrics.binary_accuracy]</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h2><ul>
<li><strong>Hold Out Validation</strong></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(x_train.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<pre><code>25000
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">num_of_validation_sample = <span class="built_in">int</span>(x_train.shape[<span class="number">0</span>]*<span class="number">0.3</span>)</span><br><span class="line"><span class="built_in">print</span>(num_of_validation_sample)</span><br></pre></td></tr></table></figure>

<pre><code>7500
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## don&#x27;t use random here , as the labels are separate</span></span><br><span class="line"></span><br><span class="line">x_val = x_train[:num_of_validation_sample]</span><br><span class="line">partial_x_train = x_train[num_of_validation_sample:]</span><br><span class="line"></span><br><span class="line">y_val = y_train[:num_of_validation_sample]</span><br><span class="line">partial_y_train = y_train[num_of_validation_sample:]</span><br></pre></td></tr></table></figure>

<h2 id="Train-Fit"><a href="#Train-Fit" class="headerlink" title="Train / Fit"></a>Train / Fit</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(</span><br><span class="line">    partial_x_train,</span><br><span class="line">    partial_y_train,</span><br><span class="line">    epochs=<span class="number">20</span>,</span><br><span class="line">    batch_size=<span class="number">512</span>,</span><br><span class="line">    validation_data=(x_val, y_val)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<pre><code>Train on 17500 samples, validate on 7500 samples
Epoch 1/20
17500/17500 [==============================] - 13s 757us/sample - loss: 0.5067 - binary_accuracy: 0.7964 - val_loss: 0.3647 - val_binary_accuracy: 0.8772
Epoch 2/20
17500/17500 [==============================] - 7s 407us/sample - loss: 0.2882 - binary_accuracy: 0.9059 - val_loss: 0.2963 - val_binary_accuracy: 0.8887
Epoch 3/20
17500/17500 [==============================] - 4s 252us/sample - loss: 0.2097 - binary_accuracy: 0.9323 - val_loss: 0.2727 - val_binary_accuracy: 0.8960
Epoch 4/20
17500/17500 [==============================] - 10s 569us/sample - loss: 0.1700 - binary_accuracy: 0.9434 - val_loss: 0.2978 - val_binary_accuracy: 0.8800
Epoch 5/20
17500/17500 [==============================] - 4s 214us/sample - loss: 0.1369 - binary_accuracy: 0.9557 - val_loss: 0.2879 - val_binary_accuracy: 0.8908
Epoch 6/20
17500/17500 [==============================] - 2s 143us/sample - loss: 0.1157 - binary_accuracy: 0.9625 - val_loss: 0.3057 - val_binary_accuracy: 0.8840
Epoch 7/20
17500/17500 [==============================] - 3s 153us/sample - loss: 0.0958 - binary_accuracy: 0.9696 - val_loss: 0.3219 - val_binary_accuracy: 0.8828
Epoch 8/20
17500/17500 [==============================] - 3s 165us/sample - loss: 0.0773 - binary_accuracy: 0.9771 - val_loss: 0.3429 - val_binary_accuracy: 0.8831
Epoch 9/20
17500/17500 [==============================] - 3s 148us/sample - loss: 0.0654 - binary_accuracy: 0.9813 - val_loss: 0.3752 - val_binary_accuracy: 0.8797
Epoch 10/20
17500/17500 [==============================] - 3s 148us/sample - loss: 0.0518 - binary_accuracy: 0.9865 - val_loss: 0.3988 - val_binary_accuracy: 0.8792
Epoch 11/20
17500/17500 [==============================] - 4s 230us/sample - loss: 0.0428 - binary_accuracy: 0.9893 - val_loss: 0.4315 - val_binary_accuracy: 0.8775
Epoch 12/20
17500/17500 [==============================] - 2s 122us/sample - loss: 0.0341 - binary_accuracy: 0.9923 - val_loss: 0.4669 - val_binary_accuracy: 0.8756
Epoch 13/20
17500/17500 [==============================] - 2s 114us/sample - loss: 0.0286 - binary_accuracy: 0.9935 - val_loss: 0.4983 - val_binary_accuracy: 0.8735
Epoch 14/20
17500/17500 [==============================] - 2s 100us/sample - loss: 0.0222 - binary_accuracy: 0.9957 - val_loss: 0.5291 - val_binary_accuracy: 0.8741
Epoch 15/20
17500/17500 [==============================] - 2s 102us/sample - loss: 0.0169 - binary_accuracy: 0.9971 - val_loss: 0.5658 - val_binary_accuracy: 0.8704
Epoch 16/20
17500/17500 [==============================] - 2s 98us/sample - loss: 0.0145 - binary_accuracy: 0.9970 - val_loss: 0.5996 - val_binary_accuracy: 0.8695
Epoch 17/20
17500/17500 [==============================] - 2s 99us/sample - loss: 0.0126 - binary_accuracy: 0.9976 - val_loss: 0.6323 - val_binary_accuracy: 0.8707
Epoch 18/20
17500/17500 [==============================] - 2s 103us/sample - loss: 0.0054 - binary_accuracy: 0.9999 - val_loss: 0.6702 - val_binary_accuracy: 0.8697
Epoch 19/20
17500/17500 [==============================] - 2s 100us/sample - loss: 0.0093 - binary_accuracy: 0.9978 - val_loss: 0.7070 - val_binary_accuracy: 0.8671
Epoch 20/20
17500/17500 [==============================] - 2s 92us/sample - loss: 0.0066 - binary_accuracy: 0.9984 - val_loss: 0.7420 - val_binary_accuracy: 0.8665
</code></pre>
<p><strong>Note that the call to <code>model.fit()</code> returns a <code>history</code> object.<br>This object has a member history, which is a dictionary containing data about everything<br>that happened during training. Let’s take a look at it:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">history_dict = history.history</span><br><span class="line">history_dict.keys()</span><br></pre></td></tr></table></figure>




<pre><code>dict_keys([&#39;loss&#39;, &#39;binary_accuracy&#39;, &#39;val_loss&#39;, &#39;val_binary_accuracy&#39;])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">acc = history.history[<span class="string">&#x27;binary_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_binary_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">epochs = <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(acc) + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &quot;bo&quot; is for &quot;blue dot&quot;</span></span><br><span class="line">plt.plot(epochs, loss, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training loss&#x27;</span>)</span><br><span class="line"><span class="comment"># b is for &quot;solid blue line&quot;</span></span><br><span class="line">plt.plot(epochs, val_loss, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation loss&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_27_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">plt.clf()   <span class="comment"># clear figure</span></span><br><span class="line"></span><br><span class="line">plt.plot(epochs, acc, <span class="string">&#x27;bo&#x27;</span>, label=<span class="string">&#x27;Training acc&#x27;</span>)</span><br><span class="line">plt.plot(epochs, val_acc, <span class="string">&#x27;b&#x27;</span>, label=<span class="string">&#x27;Validation acc&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and validation accuracy&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="output_28_0.png" alt="png"></p>
<p><strong>As you can see, the training loss decreases with every epoch and the training accuracy increases with every epoch. That’s what you would expect when running gradient descent optimization – the quantity you are trying to minimize should get lower with every iteration</strong></p>
<p><strong>But that isn’t the case for the validation loss and accuracy: they seem to peak at the fourth epoch. This is an example of what we were warning against earlier: a model that performs better on the training data isn’t necessarily a model that will do better on data it has never seen before</strong></p>
<p><strong>In precise terms, what you are seeing is “overfitting”: after the second epoch, we are over-optimizing on the training data, and we ended up learning representations that are specific to the training data and do not generalize to data outside of the training set.</strong></p>
<p><strong>In this case, to prevent overfitting, we could simply stop training after three epochs.</strong></p>
<h2 id="Evaluate"><a href="#Evaluate" class="headerlink" title="Evaluate"></a>Evaluate</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">results = model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>25000/25000 [==============================] - 5s 213us/sample - loss: 0.8104 - binary_accuracy: 0.8513
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure>

<pre><code>[0.8104157666528224, 0.85132]
</code></pre>
<h2 id="Avoiding-Overfitting"><a href="#Avoiding-Overfitting" class="headerlink" title="Avoiding Overfitting"></a>Avoiding Overfitting</h2><p><strong>from the graph we can see , it starts overfitting after 4th epoch</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(LIMIT_WORD,)))</span><br><span class="line">model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">    loss=losses.binary_crossentropy,</span><br><span class="line">    metrics=[metrics.binary_accuracy]</span><br><span class="line">)</span><br><span class="line">model.fit(</span><br><span class="line">    x_train,</span><br><span class="line">    y_train,</span><br><span class="line">    epochs=<span class="number">4</span>,</span><br><span class="line">    batch_size=<span class="number">512</span></span><br><span class="line">)</span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>Train on 25000 samples
Epoch 1/4
25000/25000 [==============================] - 5s 206us/sample - loss: 0.4753 - binary_accuracy: 0.8172
Epoch 2/4
25000/25000 [==============================] - 2s 84us/sample - loss: 0.2724 - binary_accuracy: 0.9065
Epoch 3/4
25000/25000 [==============================] - 2s 75us/sample - loss: 0.2076 - binary_accuracy: 0.9272
Epoch 4/4
25000/25000 [==============================] - 2s 75us/sample - loss: 0.1720 - binary_accuracy: 0.9402
25000/25000 [==============================] - 6s 229us/sample - loss: 0.2931 - binary_accuracy: 0.8841 - ETA: 2s - loss: 0.2995 - binary_accuracy: 0.8803 - ETA: 1s - loss: 0.3016 - binary_accuracy: 0.8796
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(results)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[0.2931446085309982, 0.88408]
</code></pre>
<h2 id="Prediction"><a href="#Prediction" class="headerlink" title="Prediction"></a>Prediction</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.predict(x_test)</span><br></pre></td></tr></table></figure>




<pre><code>array([[0.21143122],
       [0.99991524],
       [0.89155275],
       ...,
       [0.13420637],
       [0.09828689],
       [0.69260585]], dtype=float32)
</code></pre>
<h2 id="K-Fold-Cross-Validation"><a href="#K-Fold-Cross-Validation" class="headerlink" title="K Fold Cross Validation"></a>K Fold Cross Validation</h2><p><strong>we can get an idea about how our model will perform at unknown sets</strong></p>
<p><strong>that is why we are always instantiating new model</strong></p>
<p><strong>we can tune our model or the hyperparameters by doing cross validation</strong></p>
<p><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation?newreg=9eee23e22a2c4012aa70e069c76b32c4">https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation?newreg=9eee23e22a2c4012aa70e069c76b32c4</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_model</span>():</span></span><br><span class="line">    model = models.Sequential()</span><br><span class="line">    model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(LIMIT_WORD,)))</span><br><span class="line">    model.add(layers.Dense(<span class="number">16</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">    model.add(layers.Dense(<span class="number">1</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">compile</span>(</span><br><span class="line">        optimizer=optimizers.RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">        loss=losses.binary_crossentropy,</span><br><span class="line">        metrics=[metrics.binary_accuracy]</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">num_of_validation_sample = <span class="built_in">int</span>(x_train.shape[<span class="number">0</span>]*<span class="number">0.2</span>)</span><br><span class="line"><span class="built_in">print</span>(num_of_validation_sample)</span><br><span class="line">validation_scores = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fold <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    x_val = x_train[num_of_validation_sample*fold : num_of_validation_sample*(fold+<span class="number">1</span>)]</span><br><span class="line">    <span class="built_in">print</span>(x_val.shape)</span><br><span class="line">    part1_x = x_train[:num_of_validation_sample*fold]</span><br><span class="line">    part2_x = x_train[num_of_validation_sample*(fold+<span class="number">1</span>):]</span><br><span class="line">    partial_x_train = np.append(part1_x,part2_x,axis=<span class="number">0</span>)</span><br><span class="line">    <span class="built_in">print</span>(partial_x_train.shape)</span><br><span class="line"></span><br><span class="line">    y_val = y_train[num_of_validation_sample*fold : num_of_validation_sample*(fold+<span class="number">1</span>)]</span><br><span class="line">    part1_y = y_train[:num_of_validation_sample*fold]</span><br><span class="line">    part2_y = y_train[num_of_validation_sample*(fold+<span class="number">1</span>):]</span><br><span class="line">    partial_y_train = np.append(part1_y,part2_y,axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    model = get_model()</span><br><span class="line">    model.fit(</span><br><span class="line">        partial_x_train,</span><br><span class="line">        partial_y_train,</span><br><span class="line">        epochs=<span class="number">4</span>,</span><br><span class="line">        batch_size=<span class="number">512</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    results = model.evaluate(x_val, y_val)</span><br><span class="line">    validation_scores.append(results[<span class="number">1</span>])</span><br><span class="line">    <span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure>

<pre><code>5000
(5000, 10000)
(20000, 10000)
Train on 20000 samples
Epoch 1/4
20000/20000 [==============================] - 3s 133us/sample - loss: 0.4727 - binary_accuracy: 0.8161
Epoch 2/4
20000/20000 [==============================] - 2s 78us/sample - loss: 0.2763 - binary_accuracy: 0.9061
Epoch 3/4
20000/20000 [==============================] - 2s 77us/sample - loss: 0.2077 - binary_accuracy: 0.9286
Epoch 4/4
20000/20000 [==============================] - 1s 70us/sample - loss: 0.1702 - binary_accuracy: 0.9411
5000/5000 [==============================] - 1s 139us/sample - loss: 0.2709 - binary_accuracy: 0.8944
[0.2709195018291473, 0.8944]
(5000, 10000)
(20000, 10000)
Train on 20000 samples
Epoch 1/4
20000/20000 [==============================] - 5s 273us/sample - loss: 0.5080 - binary_accuracy: 0.7980
Epoch 2/4
20000/20000 [==============================] - 1s 69us/sample - loss: 0.3060 - binary_accuracy: 0.9003
Epoch 3/4
20000/20000 [==============================] - 1s 72us/sample - loss: 0.2239 - binary_accuracy: 0.9242
Epoch 4/4
20000/20000 [==============================] - 1s 65us/sample - loss: 0.1802 - binary_accuracy: 0.9378
5000/5000 [==============================] - 1s 131us/sample - loss: 0.2654 - binary_accuracy: 0.8962
[0.2653677617073059, 0.8962]
(5000, 10000)
(20000, 10000)
Train on 20000 samples
Epoch 1/4
20000/20000 [==============================] - 3s 129us/sample - loss: 0.4807 - binary_accuracy: 0.7968
Epoch 2/4
20000/20000 [==============================] - 2s 79us/sample - loss: 0.2740 - binary_accuracy: 0.9079
Epoch 3/4
20000/20000 [==============================] - 2s 91us/sample - loss: 0.2047 - binary_accuracy: 0.9299
Epoch 4/4
20000/20000 [==============================] - 1s 75us/sample - loss: 0.1675 - binary_accuracy: 0.9445
5000/5000 [==============================] - 1s 199us/sample - loss: 0.2939 - binary_accuracy: 0.8858
[0.29388200962543487, 0.8858]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val_score = np.average(validation_scores)</span><br><span class="line"><span class="built_in">print</span>(val_score)</span><br></pre></td></tr></table></figure>

<pre><code>0.8921334
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = get_model()</span><br><span class="line">model.fit(</span><br><span class="line">    x_train,</span><br><span class="line">    y_train,</span><br><span class="line">    epochs=<span class="number">4</span>,</span><br><span class="line">    batch_size=<span class="number">512</span></span><br><span class="line">)</span><br><span class="line">results = model.evaluate(x_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure>

<pre><code>Train on 25000 samples
Epoch 1/4
25000/25000 [==============================] - 5s 211us/sample - loss: 0.4542 - binary_accuracy: 0.8146
Epoch 2/4
25000/25000 [==============================] - 3s 135us/sample - loss: 0.2576 - binary_accuracy: 0.9096
Epoch 3/4
25000/25000 [==============================] - 3s 103us/sample - loss: 0.1981 - binary_accuracy: 0.9294
Epoch 4/4
25000/25000 [==============================] - 2s 82us/sample - loss: 0.1670 - binary_accuracy: 0.9399
25000/25000 [==============================] - 6s 231us/sample - loss: 0.3200 - binary_accuracy: 0.8750
[0.31998701528549195, 0.875]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/dummy/">Home</a></li>
         
          <li><a href="/dummy/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Supervised-Learning-Binary-Classification"><span class="toc-number">1.</span> <span class="toc-text">Supervised Learning : Binary Classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Importing-Dependencies"><span class="toc-number">1.1.</span> <span class="toc-text">Importing Dependencies</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Importing-Dataset"><span class="toc-number">1.2.</span> <span class="toc-text">Importing Dataset</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Preparing-the-data"><span class="toc-number">1.3.</span> <span class="toc-text">Preparing the data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Building-the-neural-network"><span class="toc-number">1.4.</span> <span class="toc-text">Building the neural network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Architecture"><span class="toc-number">1.4.1.</span> <span class="toc-text">Architecture</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Compile"><span class="toc-number">1.4.2.</span> <span class="toc-text">Compile</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Validation"><span class="toc-number">1.5.</span> <span class="toc-text">Validation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Train-Fit"><span class="toc-number">1.6.</span> <span class="toc-text">Train &#x2F; Fit</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Evaluate"><span class="toc-number">1.7.</span> <span class="toc-text">Evaluate</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Avoiding-Overfitting"><span class="toc-number">1.8.</span> <span class="toc-text">Avoiding Overfitting</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prediction"><span class="toc-number">1.9.</span> <span class="toc-text">Prediction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#K-Fold-Cross-Validation"><span class="toc-number">1.10.</span> <span class="toc-text">K Fold Cross Validation</span></a></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://zarif98sjs.github.io/dummy/BinaryClassification/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&text="><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&is_video=false&description="><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=&body=Check out this article: https://zarif98sjs.github.io/dummy/BinaryClassification/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&title="><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://zarif98sjs.github.io/dummy/BinaryClassification/&name=&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://zarif98sjs.github.io/dummy/BinaryClassification/&t="><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2019-2021
    Md. Zarif Ul Alam
  </div>
  <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/dummy/">Home</a></li>
         
          <li><a href="/dummy/archives/">Archive</a></li>
         
          <li><a href="https://zarif98sjs.github.io/">About Me</a></li>
        
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->
 
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script> 




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script> 
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/dummy/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Umami Analytics -->

<!-- Disqus Comments -->


</body>
</html>
